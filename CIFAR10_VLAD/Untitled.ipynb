{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "class progressBar:\n",
    "    def __init__(self):\n",
    "            self.bar = progressbar.ProgressBar(maxval=1, \\\n",
    "                                  widgets=[progressbar.Bar('=','[',']'), ' ', progressbar.Percentage()])\n",
    "            self.bar.start()\n",
    "    \n",
    "    def update(self,value):\n",
    "        self.bar.update(value)\n",
    "\n",
    "    def restart(self):\n",
    "        self.bar.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VLAD:\n",
    "\n",
    "    def __init__(self,x_train,x_test):\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "\n",
    "\n",
    "    def cluster_formation(self,number_of_clusters):\n",
    "        print(\"Performing KMeans Clustering\",\"-\"*(100-len(\"Performing KMeans Clustering\")))\n",
    "        keypoints = []\n",
    "        counter=1\n",
    "        bar = progressBar()\n",
    "        for image in self.x_train :\n",
    "            # image = self.resize2SquareKeepingAspectRation(image,150)\n",
    "            bar.update(counter/len(list(self.x_train)))\n",
    "            image = cv2.resize(image,(150,150))\n",
    "            image =cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "            surf = cv2.xfeatures2d.SURF_create()\n",
    "            kp, descriptors = surf.detectAndCompute(image,None)\n",
    "            keypoints.append(descriptors)\n",
    "            counter+=1\n",
    "        keypoints = np.concatenate(keypoints, axis=0)\n",
    "        self.kmeans = KMeans(n_clusters = number_of_clusters).fit(keypoints)\n",
    "        print(\"KMeans Clustering finished\",\"-\"*(100-len(\"KMeans Clustering finished\")))\n",
    "        return self.kmeans\n",
    "    \n",
    "    def vlad(self,descriptors,number_of_clusters):\n",
    "        dist_sum = []\n",
    "        for i in range(number_of_clusters):\n",
    "            dist_sum.append(np.zeros(64))\n",
    "        predict_kmeans = self.kmeans.predict(descriptors)\n",
    "        cluster_centers = self.kmeans.cluster_centers_\n",
    "        for i in range(len(descriptors)):\n",
    "            dist_sum[predict_kmeans[i]] += (np.asarray(descriptors[i]) - cluster_centers[predict_kmeans[i]])\n",
    "        dist_sum = np.asarray(dist_sum)\n",
    "        V = dist_sum.flatten()\n",
    "        V = V/np.sqrt(np.dot(V,V))\n",
    "        return V\n",
    "\n",
    "    \n",
    "    def vlad_features(self,number_of_clusters):\n",
    "        self.cluster_formation(number_of_clusters)\n",
    "        print(\"Performing VLAD extraction\",\"-\"*(100-len(\"Performing VLAD extraction\")))\n",
    "        x_feat_train = []\n",
    "        x_feat_test = []\n",
    "        counter=1\n",
    "        bar = progressBar()\n",
    "        for n in range(2):\n",
    "            if(n==0): dataset = self.x_train\n",
    "            else: dataset = self.x_test\n",
    "            for image in dataset:\n",
    "                # image = self.resize2SquareKeepingAspectRation(image,150)\n",
    "                bar.update(counter/(len(list(self.x_train))+len(list(self.x_test))))\n",
    "                image = cv2.resize(image,(150,150))\n",
    "                image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "                surf = cv2.xfeatures2d.SURF_create()\n",
    "                kp, descriptors = surf.detectAndCompute(image,None)\n",
    "#                 V = VLADL(descriptors,self.kmeans)\n",
    "                V = self.vlad(descriptors,number_of_clusters)\n",
    "                if(n==0): x_feat_train.append(V)\n",
    "                else: x_feat_test.append(V)\n",
    "                counter+=1\n",
    "        print(\"VLAD extraction finished\",\"-\"*(100-len(\"VLAD extraction finished\")))\n",
    "        return (x_feat_train,x_feat_test)\n",
    "\n",
    "    def resize2SquareKeepingAspectRation(self,img, size, interpolation = cv2.INTER_AREA):\n",
    "        h, w = img.shape[:2]\n",
    "        c = None if len(img.shape) < 3 else img.shape[2]\n",
    "        if h == w: return cv2.resize(img, (size, size), interpolation)\n",
    "        if h > w: dif = h\n",
    "        else: dif = w\n",
    "        x_pos = int((dif - w)/2.)\n",
    "        y_pos = int((dif - h)/2.)\n",
    "        if c is None:\n",
    "            mask = np.zeros((dif, dif), dtype=img.dtype)\n",
    "            mask[y_pos:y_pos+h, x_pos:x_pos+w] = img[:h, :w]\n",
    "        else:\n",
    "            mask = np.zeros((dif, dif, c), dtype=img.dtype)\n",
    "            mask[y_pos:y_pos+h, x_pos:x_pos+w, :] = img[:h, :w, :]\n",
    "        return cv2.resize(mask, (size, size), interpolation)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10:\n",
    "    \n",
    "        def __init__(self,path,number_of_clusters):\n",
    "            x_train, y_train = self.load_cfar10_batch(path,1)\n",
    "            x_train = np.asarray(x_train)\n",
    "            y_train = np.asarray(y_train)\n",
    "            self.xTrain, self.xTest, self.yTrain, self.yTest = train_test_split(x_train, y_train, test_size = 0.2, random_state = 0)\n",
    "            print(\"Number of Training Images: {}\".format(x_train.shape[0]))\n",
    "            vlad = VLAD(self.xTrain, self.xTest)\n",
    "            (self.x_feat_train,self.x_feat_test) = vlad.vlad_features(number_of_clusters)\n",
    "    \n",
    "        def load_cfar10_batch(self,cifar10_dataset_folder_path, batch_id):\n",
    "            for i in range(1,6):\n",
    "                with open(cifar10_dataset_folder_path + '/data_batch_' + str(i), mode='rb') as file:\n",
    "                    # note the encoding type is 'latin1'\n",
    "                    batch = pickle.load(file, encoding='latin1')\n",
    "                    \n",
    "                feature = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "                label = batch['labels']\n",
    "                \n",
    "                feature = np.array(feature)\n",
    "                label = np.array(label)\n",
    "                if(i==1):    \n",
    "                    features = feature\n",
    "                    labels = label\n",
    "                else:\n",
    "                    features = np.vstack((features,feature))\n",
    "                    labels = np.concatenate((labels,label))\n",
    "            return features, labels\n",
    "        \n",
    "        def random_forest(self):\n",
    "            print(\"Training Model\",\"-\"*(100-len(\"Training Model\")))\n",
    "\n",
    "            # self.rf =KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "            self.rf = RandomForestClassifier(n_estimators = 1000)\n",
    "            self.rf.fit(self.x_feat_train, self.yTrain)\n",
    "\n",
    "            y_pred = self.rf.predict(self.x_feat_test)\n",
    "            accuracy = accuracy_score(y_pred, self.yTest)\n",
    "            print(\"Acuuracy of Model: {}\".format(accuracy))\n",
    "            return confusion_matrix(self.yTest, y_pred)\n",
    "        \n",
    "        def SVM(self):\n",
    "            self.clf = svm.LinearSVC(multi_class='ovr')\n",
    "            self.clf.fit(self.x_feat_train, self.yTrain)\n",
    "\n",
    "            y_pred = self.clf.predict(self.x_feat_test)\n",
    "            accuracy = accuracy_score(y_pred, self.yTest)\n",
    "            print(\"Acuuracy of Model: {}\".format(accuracy))\n",
    "            return confusion_matrix(self.yTest, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                                                                        ]   0%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Images: 50000\n",
      "Performing KMeans Clustering ------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                                                                        ]   0%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans Clustering finished --------------------------------------------------------------------------\n",
      "Performing VLAD extraction --------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[======================================================================= ]  99%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLAD extraction finished ----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "x = CIFAR10(\"../assignment2/data/cifar-10-batches-py\",60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy of Model: 0.4281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[549,  49,  60,  25,  30,  31,  22,  60, 125,  53],\n",
       "       [ 40, 550,  24,  31,  18,  38,  46,  38,  45, 156],\n",
       "       [145,  50, 230,  74, 109,  96, 118,  89,  79,  26],\n",
       "       [ 49,  68,  85, 198,  91, 166, 149,  80,  65,  79],\n",
       "       [ 46,  32,  77,  74, 323,  53, 161, 114,  43,  44],\n",
       "       [ 39,  45,  54, 107,  71, 361,  84,  96,  54, 105],\n",
       "       [ 16,  42,  37,  62,  85,  56, 565,  31,  26,  33],\n",
       "       [ 53,  52,  54,  56,  93,  75,  46, 432,  47,  91],\n",
       "       [128,  81,  46,  26,  42,  43,  33,  35, 494,  61],\n",
       "       [ 35, 138,  19,  44,  40,  36,  51,  50,  48, 579]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "x.SVM()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sift",
   "language": "python",
   "name": "sift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
